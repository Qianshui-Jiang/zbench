{
    "$schema": "./_schema.json",

    "resources":
    {
		"query": 
        {
            "initialValues": { "sourcePath": "./flash_decoding_json/tensor_file/q_tensor_small.npy" }
        },
        "key": 
        {
            "initialValues": { "sourcePath": "./flash_decoding_json/tensor_file/k_tensor_small.npy" }
        },
        "value": 
        {
            "initialValues": { "sourcePath": "./flash_decoding_json/tensor_file/v_tensor_small.npy" }
        },
		"past_seq_len": 
        {
            "initialValues": { "sourcePath": "./flash_decoding_json/tensor_file/past_seq_len_tensor_small.npy" }
        },
        "present_key": 
        {
            "initialValues": { "sourcePath": "./flash_decoding_json/tensor_file/present_k_tensor_small.npy" }
        },
        "present_value": 
        {
            "initialValues": { "sourcePath": "./flash_decoding_json/tensor_file/present_v_tensor_small.npy" }
        },
        "output": 
        {
            "initialValuesDataType": "FLOAT16",
            "initialValues": { "valueCount": 32, "value": 0 }
        }
    },

    "dispatchables":
    {
        "mha": 
        {
            "type": "DML_OPERATOR_MULTIHEAD_ATTENTION1",
            "desc": 
            {
                "QueryTensor": { "DataType": "FLOAT16", "Sizes":  [1, 1, 1, 32] },
                "KeyTensor": { "DataType": "FLOAT16", "Sizes":    [1, 1, 1, 32] },
                "ValueTensor": { "DataType": "FLOAT16", "Sizes":  [1, 1, 1, 32] },
                "PastSequenceLengthsTensor": { "DataType": "INT32", "Sizes": [1, 1, 1, 1, 1] },
                "OutputTensor": { "DataType": "FLOAT16", "Sizes": [1, 1, 1, 32] },
                "OutputPresentKeyTensor": { "DataType": "FLOAT16", "Sizes":    [1, 4, 16, 8] },
                "OutputPresentValueTensor": { "DataType": "FLOAT16", "Sizes":  [1, 4, 16, 8] },
                "Scale": 0.0883883,
                "MaskFilterValue": -10000,
                "QueryHeadCount": 4,
                "KeyValueHeadCount": 4,
                "MaskType": "DML_MULTIHEAD_ATTENTION_MASK_TYPE_NONE"
            },
            "executionFlags":[
                "DML_EXECUTION_FLAG_ALLOW_HALF_PRECISION_COMPUTATION"
            ]
        }
    },

    "commands":
    [
        {
            "type": "dispatch",
            "dispatchable": "mha",
            "bindings": 
            {
                "QueryTensor": "query",
                "KeyTensor": "key",
                "ValueTensor": "value",
                "PastSequenceLengthsTensor": "past_seq_len",
                "OutputTensor": "output",
                "OutputPresentKeyTensor": "present_key",
                "OutputPresentValueTensor": "present_value"
            }
        },
		{    "type": "writeFile", "targetPath": "./flash_decoding_json/tensor_file/dml_mha_q_k_v_query_small.npy", "resource": "query"},
		{    "type": "writeFile", "targetPath": "./flash_decoding_json/tensor_file/dml_mha_q_k_v_key_small.npy", "resource": "key"},
		{    "type": "writeFile", "targetPath": "./flash_decoding_json/tensor_file/dml_mha_q_k_v_value_small.npy", "resource": "value"},
        {    "type": "writeFile", "targetPath": "./flash_decoding_json/tensor_file/dml_mha_q_k_v_past_seq_len_small.npy", "resource": "past_seq_len"},
		{    "type": "writeFile", "targetPath": "./flash_decoding_json/tensor_file/dml_mha_q_k_v_present_key_small.npy", "resource": "present_key"},
		{    "type": "writeFile", "targetPath": "./flash_decoding_json/tensor_file/dml_mha_q_k_v_present_value_small.npy", "resource": "present_value"},
		{    "type": "writeFile", "targetPath": "./flash_decoding_json/tensor_file/dml_mha_q_k_v_output_small.npy", "resource": "output"} 
    ]
}